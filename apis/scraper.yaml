# This is a swagger description of the Bazardelux Scraper API

swagger: '2.0'
info:
  title: Bazardelux Scraper API
  version: "0.0.1"
  description: |

    This is the Bazardelux Scraper API.

    # OpenAPI Specification

    The OpenAPI specification (aka Swagger specification) for the Bazardelux
    Scraper API is available
    [here](https://scraper.bazardelux.com/docs/scraper.yaml).

    # Authentication

    All API endpoints require authentication.

    Authentication is achieved by passing a JWT token in the HTTP Authorization
    header:

    `Authorization: Bearer {jwt token}`

    # Errors

    If an api call fails, a json Error object is returned. It typically looks like

    ```
    {
        "error": "INVALID_USER",                       # Code identifying this error
        "error_description": "Some cryptic message",   # Developer friendly explanation
        "user_message": "Invalid user",                # End-user friendly explanation
        "status": 401                                  # Same as the response's HTTP status code
    }
    ```

    # Common error codes

    All API endpoints that require authentication may return the following errors:

    * TOKEN_EXPIRED: The JWT token has expired.
    * AUTHORIZATION_HEADER_MISSING: This api call requires authentication, but the Authorization header was missing.
    * TOKEN_INVALID: This token is invalid or corrupt.

    All API endpoints that take arguments (in the query path, or parameters, or body)
    may return the error:

    * INVALID_PARAMETER: Some of the parameters sent have wrong formats.

    Any error with a status code >= 500 indicates an internal server
    error. Those errors automatically trigger an internal alert and will be
    acted upon.

    Further errors specific to given API endpoints are described in the
    endpoint's definition.

    # Date formats

    All dates are expressed in the form 'YYYY-MM-DD', as in '2016-10-16'.


host: scraper.bazardelux.com
schemes:
  - https
basePath: /v1
produces:
  - application/json
paths:

  /v1/scraper/scan:
    post:
      summary: Scan a website's listing page for objects.
      description:

        Asynchronously scan a marketplace's listing page for new announces.
        Found announces are queued up while waiting to be retrieved with
        'v1/results'.

        The scraper will scan a segment of pages within an interval of
        publication time, scanned backward in time, with the first announce
        having the most recent publication date (epoch_youngest), and the last
        announce being the oldest (epoch_oldest).

        The boundaries of the scanned interval are defined via the the
        following filters.

        * epoch_youngest - The first item to match will have been published
          before this epoch. Defaults to now.

        * epoch_oldest - The last item to match will have been published
          after this epoch. Defaults to now minus one day.

        * limit_count=N - Will retrieve only the first N mathching items.

        * limit_sec=X - Will stop scanning for items after X seconds have
        elapsed.

        This endpoint returns the start and stop epochs of the time interval
        that will be scanned.

        Matching items are directly pushed to the BDL API for processing.

      parameters:
        - in: body
          name: body
          description: How to scan this source.
          required: true
          schema:
            $ref: "#/definitions/ScanSettings"

      tags:
        - Scraper
      produces:
        - application/json
      x-bind-server: scraper.api.do_scan_source
      x-bind-client: scan_source
      x-decorate-server: pymacaron.auth.requires_auth
      x-decorate-request: pymacaron.auth.add_auth
      responses:
        '200':
          description: Matching items, or none
          schema:
            $ref: '#/definitions/ScrapedObjects'
        default:
          description: Error
          schema:
            $ref: '#/definitions/Error'


  /v1/scraper/scrape:
    post:
      summary: Scrape a specific page.
      description:

        Scrape a specific page on the source site.

        Look first at whether this announce is sold or has been removed, and
        return at once if it has. Otherwise, scrape it as thoroughly as
        possible and return the scraped data.

      parameters:
        - in: body
          name: body
          description: How to scan this source.
          required: true
          schema:
            $ref: "#/definitions/ScrapeSettings"

      tags:
        - Scraper
      produces:
        - application/json
      x-bind-server: scraper.api.do_scrape_source
      x-bind-client: scrape_page
      x-decorate-server: pymacaron.auth.requires_auth
      x-decorate-request: pymacaron.auth.add_auth
      responses:
        '200':
          description: Matching items
          schema:
            $ref: '#/definitions/ScrapedObjects'
        default:
          description: Error
          schema:
            $ref: '#/definitions/Error'


definitions:

  ScanSettings:
    type: object
    description: What source to scan and how.
    properties:
      source:
        type: string
        description: Where are those scraped objects from?
        enum:
          - BLOCKET
          - TRADERA
          - TEST
      epoch_youngest:
        description: Start scanning at first announce earlier than that epoch (Default to now).
        type: number
      epoch_oldest:
        description: End scanning at first announce earlier than that epoch.
        type: number
      limit_count:
        description: Stop searching after that many items (Default 1000).
        type: number
      limit_sec:
        description: Stop searching after that much time (Default 30 sec).
        type: number
      async:
        description: If true (default), scan asynchronously in the background and return no objects. If false, scan synchronously and return all scanned objects.
        type: boolean
      html:
        type: string
        description: (Optional) An HTML landing page to scan instead of fetching the live one.
    required:
      - source


  ScrapeSettings:
    type: object
    description: A page to scrape and how.
    properties:
      source:
        type: string
        description: Where are those scraped objects from?
        enum:
          - BLOCKET
          - TRADERA
          - TEST
      native_url:
        type: string
        description: URL to the original web page to scrape.
      html:
        type: string
        description: (Optional) An HTML page to scrape instead of fetching that at 'native_url'.
      scraper_data:
        type: string
        description: (Optional) Extra data provided by the scraper, as a json string.
    required:
      - native_url
      - source

  ScrapedObjects:
    type: object
    description: Data from one of more scraped pages, to be processed.
    properties:
      source:
        type: string
        description: Where are those scraped objects from?
        enum:
          - FACEBOOK
          - BLOCKET
          - EBAY
          - TRADERA
          - LEBONCOIN
          - CITYBOARD
          - SHPOCK
          - TEST
      real:
        type: boolean
        description: True if those objects are real (default), false if not (test data).
      epoch_youngest:
        description: Start scanning at first announce earlier than that epoch.
        type: number
      epoch_oldest:
        description: End scanning at first announce earlier than that epoch.
        type: number
      objects:
        type: array
        description: A list of scrapped objects.
        items:
          $ref: '#/definitions/ScrapedObject'
    required:
      - source
      - index
      - objects


  ScrapedObject:
    type: object
    description: Data gathered from a scraped page.
    properties:
      is_complete:
        type: boolean
        description: True if all possible data has been extracted, False if some data can still be parsed.
      native_url:
        type: string
        description: URL to the scraped web page, used as a unique identified for this object.
      scraper_data:
        type: string
        description: (Optional) Extra data provided by the scraper The scraper/marketplace to use for scraping.
      bdlitem:
        description: (Optional) Data describing an item for sale on bazardelux.
        $ref: '#/definitions/BDLItem'
      topmodel:
        description: (Optional) Data describing a top model.
        $ref: '#/definitions/TopModel'
    required:
      - is_complete
      - native_url


  TopModel:
    type: object
    description: Profile of a top model.
    additionalProperties: true


  BDLItem:
    type: object
    description: Scraped data describing an item for sale on a p2p marketplace.
    properties:
      title:
        type: string
        description: Item title.
      price:
        type: number
        format: amount
        description: Price asked for this item.
      price_is_fixed:
        type: boolean
        description: True if item has a fixed price, false if is an auction
      currency:
        type: string
        format: currency
        description: The currency of all item prices.
      is_sold:
        type: boolean
        description: Whether this item is still for sale or not.
      price_sold:
        type: number
        format: amount
        description: (Optional) Price paid for this item, if it is sold and a price was available.
      date_sold:
        type: string
        format: date-time
        description: (Optional) Date at which this item was marked as sold.
      epoch_published:
        type: string
        description: (Optional) When this announce was published.
      native_doc_id:
        type: string
        description: (Optional) The document ID of the original announce in its marketplace (Facebook doc ID, blocket_id, tradera_id)
      native_seller_id:
        type: string
        description: (Optional) The seller ID of the original announce in its marketplace (Facebook owner ID)
      native_seller_name:
        type: string
        description: (Optional) The seller name.
      native_seller_is_shop:
        type: boolean
        description: (Optional) True if the owner is a shop, false if is a private person.
      native_group_id:
        type: string
        description: (Optional) ID of facebook group where this item is.
      native_location:
        type: string
        description: (Optional) Item location as presented on the original marketplace.
      native_external_url:
        type: string
        description: (Optional) Link to original announce (outside Facebook, for example)
      native_picture_url:
        type: string
        description: (Optional) URL to the item''s picture on the marketplace it was scrapped from.
    required:
      - is_sold


  #
  # OK / ERROR
  #


  Ok:
    type: object
    description: An empty all-went-well reply
    properties:
      ok:
        type: string


  Error:
    type: object
    description: An api error
    properties:
      status:
        type: integer
        format: int32
        description: HTTP error code.
      error:
        type: string
        description: A unique identifier for this error.
      error_description:
        type: string
        description: A humanly readable error message in the user''s selected language.
      error_id:
        type: string
        description: Unique error id for querying error trace and analytics data
      error_caught:
        type: string
        description: The internal error that was caught (if any)
      user_message:
        type: string
        description: A user-friendly error message, in the user's language, to be shown in the app's alert.
    required:
      - status
      - error
      - error_description
    example:
      status: 500
      error: SERVER_ERROR
      error_description: Expected data to send in reply but got none
      user_message: Something went wrong! Try again later.